### Read the code of conduct

Please read the code of conduct here:

[http://www.godmc.org.uk/codesofconduct.pdf](http://www.godmc.org.uk/codesofconduct.pdf)

### Updating the study information

Now please visit [this Google Docs spreadsheet](https://docs.google.com/spreadsheets/d/1iOr0ZyLr8OOmhOsHLCxoBEhanJ2K_LZG-X1YrnDFyRc/edit?usp=sharing) and enter your cohort's information. Make sure to specify that you have read the code of conduct!

### Download the scripts

To download the scripts you will need to run the following git command:

    git clone git@scmv-ieugit.epi.bris.ac.uk:gh13047/godmc.git

This will create a new directory called `godmc` which will contain the files needed to run the analysis, and directories in which to put your input data.

Ideally you should clone the scripts to a location on your server which you can interact with and which is visible to your cluster nodes. Please contact us if you have any concerns about this.

Once cloned, in the `godmc` directory you will see the following files and folders:

- `config.example` file: Your first task in setting up the pipeline is to create a `config` file. The `config.example` is a template for this and you can modify this file to point to your input data files. You can also change the various settings and parameters used for the analysis here.
- `input_data` directory: You can deposit your input data files (genotypes, methylation data, CNV data, covariates, phenotypes) into this directory. 
- `*.sh` files: These are the files that you need to run in sequence to perform the analysis. They will be explained step-by-step in this guide. **You do not need to manually change any of these files**.
- `resources` directory: This contains a number of scripts and executables that will be used by the various `.sh` scripts to run the analyses. **You do not need to manually change any of these files**.
- `processed_data` directory: This is the destination for derived data generated by the scripts. **You do not need to manually change any of these files**.
- `results` directory: This will be where the scripts store results from the analyses. **You do not need to manually change any of these files**.

Because this is a `git` repository it means that it is very easy for you to update files if for any reason changes are made. In order to update the scripts you simply run:

    git pull

Please note it is assumed that you won't change any files in the repository itself.


### Setup

The first thing to do is create your `config` file:

    cp config.example config

You can now modify the `config` file (**not** the `config.example` file!) to specify the location of your input data and the parameters that will be used for the analysis.

Open the file in a text editor, and change the entries for the following variables:

- `study_name`
- `analyst_name`
- `analyst_email`
- `home_directory`

For example if you are in the `godmc` folder then type 

    pwd

and it will give you the full path to your current directory. Set the `home_directory` variable to be this path.

### Phenotype options

If you are providing phenotypes for EWAS analysis then this can be specified in the `config` file by setting the following lines to `yes` where appropriate:

   EWAS_phenotypes="no"
   height="no"
   bmi="no"


### Input data

The folder `godmc/input_data` can be used to put input data. This will include:

- Genetic data in binary plink format. Please see [here]() for more info.
- CNV data stored in a `.RData` file. Please see [here]() for more info.
- Normalised and QC'd methyation data stored in an `.RData` file. Please see [here]() for more info.
- Phenotypes and covariates stored as plain text files. Please see [here]() for more info.


### Cellcount options

You do not need to provide cellcounts, as they can be predicted using the Houseman reference method by the pipeline. If you do not have cellcounts pre-calculated, and you know that you have heterogeneous cell types in your methylation samples, then please set the following variables:

    cellcounts_required="yes"
    provided_cellcounts="NULL"

If you have a homogeneous cell type then:

    cellcounts_required="no"
    provided_cellcounts="NULL"

If you have cellcounts available for all your methylation samples already then:

    cellcounts_required="no"
    provided_cellcounts="/path/to/cellcounts.txt"

Note that you can copy the cellcounts to the `input_data` directory and specify the path as `${home_directory}/input_data/cellcounts.txt`. Please note that the required format for pre-specified cellcount data should look like this:

    IID Bcell CD4T CD8T Gran Mono NK
    id1 0.02 0 -4.26e-18 0.82 0.06 0.11
    id2 0.08 0.16 0.01 0.53 0.05 0.21
    id3 0.06 0.12 0.07 0.56 0.08 0.16

*i.e.* An `IID` column for the sample IDs, and then one column for each cell type that has been counted (or estimated).


### Relatedness

If you have family relationships in your data (i.e. twin or family study design) then please specify this by setting the parameter:

    unrelated="no"

Otherwise set the parameter:

    unrelated="yes"

In this case the pipeline will attempt to find any cryptic related individuals and remove them.


### Computation

The pipeline uses `plink1.90` and `gcta64` which both have multi-threading capabilities. It also uses the `R/parallel` package to speed up R calculations. For some of the scripts in the pipeline these multi-threading options will be used. Please specify how many threads you have available with the following variable (e.g. if you have 16 threads available):

    nthreads="16"

In addition, some of the computationally slower processes can be parallelised across multiple nodes on a cluster. Please modify the following option to customise how many batches to split long running jobs into:

    meth_chunks="100"

The default is to split large jobs into 100 jobs.


### Other options

Other options are also modifiable, but for most cohorts the default settings should be fine. Please contact us if you are unsure.



## Checking the data

We have created a script which will check the data you have submitted to make sure it all looks as expected. It also creates a list of IDs that are in common between the different data sources, and a number of graphs to visualise the raw data. To run:

    ./01-check_data.sh

**PLEASE NOTE:** It is important to monitor this script as it runs - it will stop with errors if it encounters problems. Please fix any errors that are encountered, and re-run the script until it completes without errors.

The script produces a plot to show the number of SNPs per chromosome. At the end of the script you should be able to visually check that this looks as expected, located in `processed_data/datacheck`. 
